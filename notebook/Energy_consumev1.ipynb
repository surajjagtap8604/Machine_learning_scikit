{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy Consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT ALL REQUIRED LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler,OrdinalEncoder,OneHotEncoder\n",
    "from sklearn import feature_selection\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "data_dir = os.path.join(current_directory,\"Datasets\",\"Energy_consumption.csv\")\n",
    "data = pd.read_csv(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with cProfile.Profile() as pr:\n",
    "    #data_val.missing_v(col_ty)\n",
    "    data_val.missing_count(col_ty)\n",
    "\n",
    "stats = pstats.Stats(pr)\n",
    "stats.sort_stats(pstats.SortKey.TIME)\n",
    "#stats.print_stats()\n",
    "stats.dump_stats(filename=\"needs_profile.prof\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = template.data_val(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_ty = data_val.get_column_type()\n",
    "print(col_ty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_count(df,column_types):\n",
    "    unique= {}\n",
    "    unique_counts = {}\n",
    "    for column in df.columns:\n",
    "        if column_types[column] == \"categorical\" and column != \"Timestamp\":\n",
    "            unique[column] = pd.unique(df[column])\n",
    "            unique_counts[column] = len(unique[column])\n",
    "    uniques = { \"unique_values\" : unique,\"unique_counts\" : unique_counts}\n",
    "    return uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unique_count(data,col_ty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_count(df):\n",
    "    zero_counts = {}\n",
    "    for column in df.columns:\n",
    "        zero_counts[column] = column.count(axis=1)\n",
    "        \n",
    "    print(zero_counts)\n",
    "zero_count(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val.missing_count(col_ty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_info = data.info()\n",
    "print(\"hi\",num_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cProfile.run(\"data.info()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Timestamp\"] = pd.to_datetime(data[\"Timestamp\"])\n",
    "\n",
    "data.set_index(\"Timestamp\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "sns.relplot(data=data,x=data[\"Temperature\"],y=data[\"EnergyConsumption\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[\"Temperature\"]\n",
    "y = data[\"EnergyConsumption\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1,x_test1,y_train1,y_test1 = train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "x_train = x_train1.values.reshape(-1,1)\n",
    "y_train = y_train1.values.reshape(-1,1)\n",
    "x_test = x_test1.values.reshape(-1,1)\n",
    "y_test = y_test1.values.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(x_train, y_train)\n",
    "y_pred = regr.predict(x_test)\n",
    "print(\"Coefficients of regression : \",regr.coef_)\n",
    "print(\"mean_squared_error : %.2f\"% mean_squared_error(y_test, y_pred))\n",
    "print(\"Coefficients of determination :%.2f \"% r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = {\"Temperature\": x_train1, \"EnergyConsumpition\": y_train1, \"x_test\": x_test1, \"y_test\":y_test1}\n",
    "z= pd.DataFrame(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = regr.coef_.reshape(-1)\n",
    "b = regr.intercept_.reshape(-1)\n",
    "sns.relplot(data=z,x=\"Temperature\",y=\"EnergyConsumpition\")\n",
    "x_val = np.linspace(z[\"Temperature\"].min(),z[\"Temperature\"].max(),100)\n",
    "y_val = m*x_val + b\n",
    "plt.plot(x_val,y_val,color = \"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, an R^2 value of 0.45 suggests that the regression model has moderate predictive power, explaining a significant portion but not all of the variance in the dependent variable. However, a mean squared error of 35.81 indicates that there is still room for improvement in reducing prediction errors. So, while the model is performing decently, there is still scope for enhancement.\n",
    "\n",
    "So now we will use another algorithm\n",
    "based on type of data and their relationship we can use different algorithms such as :\n",
    "1. Multiple linear regression\n",
    "2. Decision Tree Regressor\n",
    "3. Random Forest\n",
    "4. Gradient Boosting Regressor\n",
    "5. Support Vector regressor\n",
    "6. Neural Network\n",
    "\n",
    "but from data we can see more categorical data is available so i think that decision tree and random forest can be greate algorithm which is suitable for this type of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = data.iloc[:,:9]\n",
    "y1 = data[\"EnergyConsumption\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1[\"SquareFootage\"] = x1[\"SquareFootage\"]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train,x1_test,y1_train,y1_test = train_test_split(x1,y1,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_transform(xa):\n",
    "    x2 = xa[\"HVACUsage\"].values.reshape(-1,1)\n",
    "    x3 = xa[\"LightingUsage\"].values.reshape(-1,1)\n",
    "    x4 = xa[\"DayOfWeek\"].values.reshape(-1,1)\n",
    "    x5 = xa[\"Holiday\"].values.reshape(-1,1)\n",
    "    enc = preprocessing.OneHotEncoder(drop='if_binary')\n",
    "    enc.fit(x2)\n",
    "    xa[\"HVACUsage\"] = enc.transform(x2).toarray()\n",
    "    enc = preprocessing.OneHotEncoder(drop='if_binary')\n",
    "    enc.fit(x3)\n",
    "    xa[\"LightingUsage\"] = enc.transform(x3).toarray()\n",
    "    enc = preprocessing.OneHotEncoder()\n",
    "    enc.fit(x4)\n",
    "    xa[\"DayOfWeek\"] = enc.transform(x4).toarray()\n",
    "    enc = preprocessing.OneHotEncoder(drop='if_binary')\n",
    "    enc.fit(x5)\n",
    "    xa[\"Holiday\"] = enc.transform(x5).toarray()\n",
    "    return xa\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train = pipeline_transform(x1_train)\n",
    "x1_test = pipeline_transform(x1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "reg1 = HistGradientBoostingRegressor().fit(x1_train, y1_train)\n",
    "print(reg1.score(x1_test, y1_test),reg1.score(x1_train, y1_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "reg2  = svm.SVR()\n",
    "reg2.fit(x1_train, y1_train)\n",
    "print(reg2.score(x1_test, y1_test),reg2.score(x1_train, y1_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "reg3 = make_pipeline(StandardScaler(),SGDRegressor(max_iter=1000, tol=1e-3))\n",
    "reg3.fit(x1_train, y1_train)\n",
    "print(reg3.score(x1_test, y1_test),reg3.score(x1_train, y1_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "reg4 = RandomForestRegressor(max_depth=4,random_state=42)\n",
    "reg4.fit(x1_train, y1_train)\n",
    "print(reg4.score(x1_test, y1_test),reg4.score(x1_train, y1_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "reg5 = AdaBoostRegressor(random_state=42,n_estimators=100)\n",
    "reg5.fit(x1_train, y1_train)\n",
    "print(reg5.score(x1_test, y1_test),reg5.score(x1_train, y1_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "reg6 = BaggingRegressor(estimator=SGDRegressor(max_iter=1000, tol=1e-3),random_state=42,n_estimators=100)\n",
    "\n",
    "reg6.fit(x1_train, y1_train)\n",
    "\n",
    "print(reg6.score(x1_test, y1_test),reg6.score(x1_train, y1_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming x1_train, x1_test, y1_train, y1_test are defined\n",
    "reg6 = BaggingRegressor(estimator=SGDRegressor(max_iter=1000, tol=1e-3), random_state=42, n_estimators=100)\n",
    "\n",
    "reg6.fit(x1_train, y1_train)\n",
    "\n",
    "print(reg6.score(x1_test, y1_test), reg6.score(x1_train, y1_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "ereg = VotingRegressor(estimators=[('Hgb', reg1), ('svr', reg2), ('sgd', reg3),('rd',reg4),('ada',reg5)])\n",
    "ereg.fit(x1_train, y1_train)\n",
    "print(ereg.score(x1_test, y1_test),ereg.score(x1_train, y1_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
